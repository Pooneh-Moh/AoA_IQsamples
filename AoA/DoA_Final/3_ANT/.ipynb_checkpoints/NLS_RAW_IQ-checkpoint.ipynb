{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c4a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import scipy.optimize as optimization\n",
    "from scipy.optimize import least_squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10f3dd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pakts are 68 34 42432\n",
      "42432\n"
     ]
    }
   ],
   "source": [
    "#C:\\ti\\simplelink_cc13x2_26x2_sdk_4_40_04_04\\tools\\ble5stack\\rtls_agent\\examples\\3ANT\\ofoghi\\rtls_aoa_iq_with_rtls_util_export_into_csv_3ant_AoA_log\\04_16_2021_16_55_55_rtls_raw_iq_samples_0x11_zero_f88a5e2d7808_0.csv\n",
    "# path = 'C:/ti/simplelink_cc13x2_26x2_sdk_4_40_04_04/tools/ble5stack/rtls_agent/examples/3ANT/ofoghi/rtls_aoa_iq_with_rtls_util_export_into_csv_3ant_AoA_log/04_16_2021_16_55_55_rtls_raw_iq_samples_0x11_zero_f88a5e2d7808_0.csv' # test @ 1m \n",
    "path = 'C:/Users/pooneh/Documents/GitHub/AoA_IQsamples/AoA/DoA_Final/3_ANT/3ANT_AoA/datapoints_250cm/3ANT/zero/05_04_2021_13_54_13_rtls_raw_iq_samples_f88a5e2d7808_0.csv'\n",
    "data = pd.read_csv(path)\n",
    "data_size = len(data)\n",
    "N = int(data_size/624)\n",
    "print('Number of pakts are', N, int(N/2), len(data))\n",
    "t = np.arange(0, 156*N, 0.25)\n",
    "print(len(t))\n",
    "data['time_stamp'] = t\n",
    "data['Magnitude'] = np.sqrt(np.power(data['i'], 2) + np.power(data['q'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64a753e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-23b68b2b1de6>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  t['omega'] = (t['channel']-11)*2+ 2428.25\n",
      "<ipython-input-3-23b68b2b1de6>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tless['omega'] = (tless['channel'])*2 + 2404.25\n"
     ]
    }
   ],
   "source": [
    "data['ts'] = data['time_stamp']\n",
    "t = data[data.channel >= 11]\n",
    "t['omega'] = (t['channel']-11)*2+ 2428.25\n",
    "tless = data[data.channel < 11]\n",
    "tless['omega'] = (tless['channel'])*2 + 2404.25\n",
    "data = t.append(tless)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2585d4f6",
   "metadata": {},
   "source": [
    "### NOW Optimize the RAW_IQ samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9e7ffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optomize the data from ANT1\n",
    "def s(theta, t ):\n",
    "    x = theta[0] * np.cos(2*np.pi*t*fc + phi)\n",
    "    y = theta[1] * np.sin(2*np.pi*t*fc + phi)\n",
    "    return np.array([x, y])\n",
    "\n",
    "new_i_lst = []\n",
    "new_q_lst = []\n",
    "\n",
    "phi = 0;\n",
    "for i in range(0, len(data), 624):\n",
    "    Ai = data.Magnitude[i:i+624].mean()\n",
    "    Aq = data.Magnitude[i:i+624].mean()\n",
    "    fc = data.omega[i:i+624].mean(); \n",
    "    ts = data.time_stamp[i:i+624]\n",
    "    ss = s([Ai, Aq, fc, phi], ts)\n",
    "    ss[0] += data['i'][i:i+624]\n",
    "    ss[1] += data['q'][i:i+624]\n",
    "    \n",
    "\n",
    "    def fun(theta):\n",
    "        return (ss- s(theta, ts)).flatten()\n",
    "\n",
    "    theta0 = [0,0,0,0]\n",
    "    res1 = least_squares(fun, theta0)\n",
    "    N = int(len(res1.fun)/2)\n",
    "    new_i1 = res1.fun[0:N]\n",
    "    new_i_lst.append(new_i1)\n",
    "    new_q1 = res1.fun[N:len(res1.fun)]\n",
    "    new_q_lst.append(new_q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c872b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(data['i'][0:624], data['q'][0:624])\n",
    "# plt.scatter(new_i_lst[0], new_q_lst[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cccf7377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "flatten_i = list(chain.from_iterable(new_i_lst))\n",
    "flatten_q = list(chain.from_iterable(new_q_lst))\n",
    "data['new_i'] = flatten_i\n",
    "data['new_q'] = flatten_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80b9e00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "info =[]\n",
    "data_size = len(data)\n",
    "N = int(data_size/624)\n",
    "for n in range(N):\n",
    "    for i in range(36+n*624, 624*(n+1), 8):\n",
    "        for j in range(i, i+4):\n",
    "            info.append({\"pkt\": n, \"Channel\": data['channel'][j], \"sample_idx\": data['sample_idx'][j], \n",
    "                         \"I\": data['i'][j],\n",
    "                         \"Q\":data['q'][j],\n",
    "                         \"Magnitude\": data['Magnitude'][j],\n",
    "                         \"time_stamp\": data['time_stamp'][j], \"omega\": data['omega'][j], \n",
    "                          \"new_i\": data['new_i'][j], \"new_q\": data['new_q'][j]})\n",
    "    info_dec = pd.DataFrame(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b489326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = info_dec.drop(info_dec[info_dec.sample_idx > 607].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13983d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_ant1 = []\n",
    "lst_ant2 = []\n",
    "lst_ant3 = []\n",
    "\n",
    "for i in range(0, len(df), 12):    \n",
    "    lst_ant2.append(df[i:i+4])\n",
    "    lst_ant1.append(df[i+4:i+8])\n",
    "    lst_ant3.append(df[i+8:i+12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9863056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ant1 = pd.concat(lst_ant1,  ignore_index=True)\n",
    "df_ant2 = pd.concat(lst_ant2,  ignore_index=True)\n",
    "df_ant3 = pd.concat(lst_ant3,  ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef86b1a",
   "metadata": {},
   "source": [
    "### Caluclate the phase difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00f414ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X12 = (df_ant1['I'] + 1j*df_ant1['Q']) * (df_ant2['I'] - 1j*df_ant2['Q'])\n",
    "X23 = (df_ant2['I'] + 1j*df_ant2['Q']) * (df_ant3['I'] - 1j*df_ant3['Q'])\n",
    "X13 = (df_ant1['I'] + 1j*df_ant1['Q']) * (df_ant3['I'] - 1j*df_ant3['Q'])\n",
    "X12_opt = (df_ant1['new_i'] + 1j*df_ant1['new_q']) * (df_ant2['new_i'] - 1j*df_ant2['new_q'])\n",
    "X23_opt = (df_ant2['new_i'] + 1j*df_ant2['new_q']) * (df_ant3['new_i'] - 1j*df_ant3['new_q'])\n",
    "X13_opt = (df_ant1['new_i'] + 1j*df_ant1['new_q']) * (df_ant3['new_i'] - 1j*df_ant3['new_q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edf74b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'channel': df_ant1['Channel'],'omega':df_ant1['omega']}\n",
    "data_fin = pd.DataFrame(data=d)\n",
    "data_fin['phi12'] = np.angle(X12)\n",
    "data_fin['phi23'] = np.angle(X23)\n",
    "data_fin['phi13'] = np.angle(X13)\n",
    "data_fin['mag12'] = np.abs(X12)\n",
    "data_fin['mag23'] = np.abs(X23)\n",
    "data_fin['mag13'] = np.abs(X13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3db15c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fin['phi12_opt'] = np.angle(X12_opt)\n",
    "data_fin['phi23_opt'] = np.angle(X23_opt)\n",
    "data_fin['phi13_opt'] = np.angle(X13_opt)\n",
    "data_fin['mag12_opt'] = np.abs(X12_opt)\n",
    "data_fin['mag23_opt'] = np.abs(X23_opt)\n",
    "data_fin['mag13_opt'] = np.abs(X13_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "064b5dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_channel = []\n",
    "for i in range(0, len(data_fin),96):\n",
    "    phi_channel.append({\"channel\":data_fin['channel'][i], \"omega\":data_fin['omega'][i],\n",
    "                       \"ave_phi12\": np.average(data_fin['phi12'][i:i+96]),\n",
    "                       \"ave_phi23\": np.average(data_fin['phi23'][i:i+96]),\n",
    "                        \"ave_phi13\": np.average(data_fin['phi13'][i:i+96]),\n",
    "                        \"ave_phi12_opt\": np.average(data_fin['phi12_opt'][i:i+96]),\n",
    "                       \"ave_phi23_opt\": np.average(data_fin['phi23_opt'][i:i+96]),\n",
    "                        \"ave_phi13_opt\": np.average(data_fin['phi13_opt'][i:i+96]),\n",
    "                       \"ave_mag12\": np.average(data_fin['mag12'][i:i+96]),\n",
    "                       \"ave_mag23\": np.average(data_fin['mag23'][i:i+96]),\n",
    "                       \"ave_mag13\": np.average(data_fin['mag13'][i:i+96]),})\n",
    "average_perchannel = pd.DataFrame(phi_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4dc6664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(' Angle per paire', np.average(average_perchannel['ave_phi12'])*180/np.pi, np.average(average_perchannel['ave_phi23'])*180/np.pi, np.average(average_perchannel['ave_phi13'])*180/np.pi,\n",
    "#      '\\n Total average of angle', (np.average(average_perchannel['ave_phi12'])/3+ np.average(average_perchannel['ave_phi23'])/3+ np.average(average_perchannel['ave_phi13'])/3)*180/np.pi,\n",
    "#      '\\n STD per paire', average_perchannel['ave_phi12'].std(), average_perchannel['ave_phi23'].std(), average_perchannel['ave_phi13'].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b03f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(' Angle_per paire', np.average(average_perchannel['ave_phi12_opt'])*180/np.pi, np.average(average_perchannel['ave_phi23_opt'])*180/np.pi, np.average(average_perchannel['ave_phi13_opt'])*180/np.pi,\n",
    "#      '\\n Average', (np.average(average_perchannel['ave_phi12_opt'])/3+ np.average(average_perchannel['ave_phi23_opt'])/3+ np.average(average_perchannel['ave_phi13_opt'])/3)*180/np.pi,\n",
    "#      '\\n STD', average_perchannel['ave_phi12_opt'].std(), average_perchannel['ave_phi23_opt'].std(), average_perchannel['ave_phi13_opt'].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87921aec",
   "metadata": {},
   "source": [
    "### Importing the correcting_csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9d4a363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74.98450902022674"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_coeff = 'C:/Users/pooneh/Documents/GitHub/AoA_IQsamples/AoA/DoA_Final/3_ANT/3ANT_AoA/datapoints_250cm/3ANT/zerocorrection_coeff_negative_dasti_zero_optimized.csv'\n",
    "\n",
    "df_corr = pd.read_csv(path_coeff)\n",
    "df_corr.ex_phi12.mean()*180/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "90c080eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "channl = average_perchannel.channel\n",
    "phi12_corr_ave = []\n",
    "phi23_corr_ave = []\n",
    "phi13_corr_ave = []\n",
    "phi12_corr_ave_opt = []\n",
    "phi23_corr_ave_opt = []\n",
    "phi13_corr_ave_opt = []\n",
    "# phi12_ave = []\n",
    "for ch in channl:\n",
    "    g = df_corr[df_corr.channel == ch]\n",
    "    f = average_perchannel[average_perchannel.channel == ch]\n",
    "#     print(ch, phi12_corr_ave)\n",
    "    phi12_corr_ave.append(np.average(f.ave_phi12)- np.average(g.phi12_correction))\n",
    "    phi23_corr_ave.append(np.average(f.ave_phi23)- np.average(g.phi23_correction))\n",
    "    phi13_corr_ave.append(np.average(f.ave_phi13)- np.average(g.phi13_correction))\n",
    "    phi12_corr_ave_opt.append(np.average(f.ave_phi12_opt)- np.average(g.phi12_correction))\n",
    "    phi23_corr_ave_opt.append(np.average(f.ave_phi23_opt)- np.average(g.phi23_correction))\n",
    "    phi13_corr_ave_opt.append(np.average(f.ave_phi13_opt)- np.average(g.phi13_correction))\n",
    "#     phi12_ave.append(np.average(g.phi12_correction)*180/np.pi)\n",
    "#     print(np.average(g.phi12_correction)*180/np.pi)\n",
    "\n",
    "\n",
    "# print(len(average_perchannel), np.average(phi12_ave))\n",
    "average_perchannel['corrected_phi12'] = phi12_corr_ave\n",
    "average_perchannel['corrected_phi23'] = phi23_corr_ave\n",
    "average_perchannel['corrected_phi13'] = phi13_corr_ave\n",
    "average_perchannel['corrected_phi12_opt'] = phi12_corr_ave_opt\n",
    "average_perchannel['corrected_phi23_opt'] = phi23_corr_ave_opt\n",
    "average_perchannel['corrected_phi13_opt'] = phi13_corr_ave_opt\n",
    "# np.average(phi12_corr_ave)*180/np.pi, np.average(phi23_corr_ave)*180/np.pi, np.average(phi13_corr_ave)*180/np.pi,\n",
    "# np.max(phi12_corr_ave)*180/np.pi, np.max(phi23_corr_ave)*180/np.pi, np.max(phi13_corr_ave)*180/np.pi, np.min(phi13_corr_ave)*180/np.pi,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d179d2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n average phi', (np.average(average_perchannel['ave_phi12'])*180/np.pi+ np.average(average_perchannel['ave_phi23'])*180/np.pi+ np.average(average_perchannel['ave_phi13'])*90/np.pi)/3,\n",
    "#      '\\n corrected phi_per channel', (np.average(average_perchannel['corrected_phi12'])*180/np.pi+ np.average(average_perchannel['corrected_phi13'])*90/np.pi+ np.average(average_perchannel['corrected_phi23'])*180/np.pi)/3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42d481ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(' average phi_opt', (np.average(average_perchannel['ave_phi12_opt'])*180/np.pi+ np.average(average_perchannel['ave_phi23_opt'])*180/np.pi+ np.average(average_perchannel['ave_phi13_opt'])*90/np.pi)/3,\n",
    "#      '\\n corrected phi_per_opt channel', (np.average(average_perchannel['corrected_phi12_opt'])*180/np.pi+ np.average(average_perchannel['corrected_phi13_opt'])*90/np.pi+ np.average(average_perchannel['corrected_phi23_opt'])*180/np.pi)/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5127d233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " average phi with no correction error 29.50697914699589 \n",
      " corrected phi_per channel error 0.5698244892090685 \n",
      " average phi_opt with no correction error 36.140200936015496 \n",
      " corrected phi_per_opt channel error 7.203046278228683\n"
     ]
    }
   ],
   "source": [
    "print('\\n average phi with no correction error', df_corr.ex_phi12.mean()*180/np.pi - (np.average(average_perchannel['ave_phi12'])*180/np.pi+ np.average(average_perchannel['ave_phi23'])*180/np.pi+ np.average(average_perchannel['ave_phi13'])*90/np.pi)/3,\n",
    "     '\\n corrected phi_per channel error', df_corr.ex_phi12.mean()*180/np.pi - (np.average(average_perchannel['corrected_phi12'])*180/np.pi+ np.average(average_perchannel['corrected_phi13'])*90/np.pi+ np.average(average_perchannel['corrected_phi23'])*180/np.pi)/3,\n",
    "     '\\n average phi_opt with no correction error', df_corr.ex_phi12.mean()*180/np.pi - (np.average(average_perchannel['ave_phi12_opt'])*180/np.pi+ np.average(average_perchannel['ave_phi23_opt'])*180/np.pi+ np.average(average_perchannel['ave_phi13_opt'])*90/np.pi)/3,\n",
    "     '\\n corrected phi_per_opt channel error', df_corr.ex_phi12.mean()*180/np.pi - (np.average(average_perchannel['corrected_phi12_opt'])*180/np.pi+ np.average(average_perchannel['corrected_phi13_opt'])*90/np.pi+ np.average(average_perchannel['corrected_phi23_opt'])*180/np.pi)/3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6fefa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "a12 = np.average(average_perchannel['corrected_phi12']) \n",
    "a23 = np.average(average_perchannel['corrected_phi23'])\n",
    "a13 = np.average(average_perchannel['corrected_phi13'])/2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d91fcfe",
   "metadata": {},
   "source": [
    "### Kalman Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e188a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = average_perchannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4ed359e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterpy.kalman import KalmanFilter\n",
    "from filterpy.common import Q_discrete_white_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "350de845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.328 0.467 0.2695\n"
     ]
    }
   ],
   "source": [
    "t = 2.5e-8\n",
    "error_est_x = -0.2272\n",
    "error_est_x23 = -0.3128\n",
    "error_est_x13 = -0.178\n",
    "# print(error_est_x, error_est_x23, error_est_x13)\n",
    "error_est_v = 5;\n",
    "v = 2404\n",
    "def prediction2d(x, v, t):\n",
    "    A = np.array([[1, t],\n",
    "                  [0, 1]])\n",
    "    X = np.array([[x],\n",
    "                  [v]])\n",
    "    X_prime = A.dot(X) \n",
    "    return X_prime\n",
    "\n",
    "def covariance2d(sigma1, sigma2):\n",
    "    cov1_2 = sigma1 * sigma2\n",
    "    cov2_1 = sigma2 * sigma1\n",
    "    cov_matrix = np.array([[sigma1 ** 2, cov1_2],\n",
    "                           [cov2_1, sigma2 ** 2]])\n",
    "    return np.diag(np.diag(cov_matrix))\n",
    "\n",
    "# Initial Estimation Covariance Matrix\n",
    "P = covariance2d(error_est_x, error_est_v)\n",
    "P23 = covariance2d(error_est_x23, error_est_v)\n",
    "P13 = covariance2d(error_est_x13, error_est_v)\n",
    "\n",
    "A = np.array([[1, t],\n",
    "              [0, 1]])\n",
    "\n",
    "error_obs_v = int(sdata['omega'].std())\n",
    "\n",
    "error_obs_x = 0.328\n",
    "error_obs_x23 = 0.467\n",
    "error_obs_x13 = 0.2695\n",
    "\n",
    "# x_observations = sdata['corrected_phi12']\n",
    "# x23_observations = sdata['corrected_phi23']\n",
    "# x13_observations = sdata['corrected_phi13']\n",
    "x_observations = sdata['corrected_phi12_opt']\n",
    "x23_observations = sdata['corrected_phi23_opt']\n",
    "x13_observations = sdata['corrected_phi13_opt']\n",
    "\n",
    "v_observations = sdata['omega']\n",
    "v = sdata['omega'].mean()\n",
    "z = np.c_[x_observations, v_observations]\n",
    "z23 = np.c_[x23_observations, v_observations]\n",
    "z13 = np.c_[x13_observations, v_observations]\n",
    "\n",
    "# Initial State Matrix\n",
    "X = np.array([[z[0][0]],\n",
    "              [v]])\n",
    "X23 = np.array([[z23[0][0]],\n",
    "              [v]])\n",
    "X13 = np.array([[z13[0][0]],\n",
    "              [v]])\n",
    "\n",
    "n = len(z[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dabe5709",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(len(z)):\n",
    "    for data in z[1:]:\n",
    "        X = prediction2d(X[0][0], X[1][0], t)\n",
    "        # To simplify the problem, professor\n",
    "        # set off-diagonal terms to 0.\n",
    "        P = np.diag(np.diag(A.dot(P).dot(A.T)))\n",
    "\n",
    "        # Calculating the Kalman Gain\n",
    "        H = np.identity(n)\n",
    "        R = covariance2d(error_obs_x, error_obs_v)\n",
    "        S = H.dot(P).dot(H.T) + R\n",
    "        from numpy.linalg import inv\n",
    "        K = P.dot(H).dot(inv(S))\n",
    "        del inv\n",
    "\n",
    "        # Reshape the new data into the measurement space.\n",
    "        Y = H.dot(data).reshape(n, -1)\n",
    "\n",
    "        # Update the State Matrix\n",
    "        # Combination of the predicted state, measured values, covariance matrix and Kalman Gain\n",
    "        X = X + K.dot(Y - H.dot(X))\n",
    "        \n",
    "        # Update Process Covariance Matrix\n",
    "        P = (np.identity(len(K)) - K.dot(H)).dot(P)\n",
    "    results.append(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7162d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(len(z23)):\n",
    "    for data in z23[1:]:\n",
    "        X23 = prediction2d(X23[0][0], X23[1][0], t)\n",
    "        # To simplify the problem, professor\n",
    "        # set off-diagonal terms to 0.\n",
    "        P23 = np.diag(np.diag(A.dot(P23).dot(A.T)))\n",
    "\n",
    "        # Calculating the Kalman Gain\n",
    "        H = np.identity(n)\n",
    "        R = covariance2d(error_obs_x23, error_obs_v)\n",
    "        S = H.dot(P23).dot(H.T) + R\n",
    "        from numpy.linalg import inv\n",
    "        K = P23.dot(H).dot(inv(S))\n",
    "        del inv\n",
    "\n",
    "        # Reshape the new data into the measurement space.\n",
    "        Y = H.dot(data).reshape(n, -1)\n",
    "\n",
    "        # Update the State Matrix\n",
    "        # Combination of the predicted state, measured values, covariance matrix and Kalman Gain\n",
    "        X23 = X23 + K.dot(Y - H.dot(X23))\n",
    "        \n",
    "        # Update Process Covariance Matrix\n",
    "        P = (np.identity(len(K)) - K.dot(H)).dot(P)\n",
    "    results.append(X23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f51d87b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(len(z13)):\n",
    "    for data in z13[1:]:\n",
    "        X13 = prediction2d(X13[0][0], X13[1][0], t)\n",
    "        # To simplify the problem, professor\n",
    "        # set off-diagonal terms to 0.\n",
    "        P13 = np.diag(np.diag(A.dot(P13).dot(A.T)))\n",
    "\n",
    "        # Calculating the Kalman Gain\n",
    "        H = np.identity(n)\n",
    "        R = covariance2d(error_obs_x13, error_obs_v)\n",
    "        S = H.dot(P13).dot(H.T) + R\n",
    "        from numpy.linalg import inv\n",
    "        K = P13.dot(H).dot(inv(S))\n",
    "        del inv\n",
    "\n",
    "        # Reshape the new data into the measurement space.\n",
    "        Y = H.dot(data).reshape(n, -1)\n",
    "\n",
    "        # Update the State Matrix\n",
    "        # Combination of the predicted state, measured values, covariance matrix and Kalman Gain\n",
    "        X13 = X13 + K.dot(Y - H.dot(X13))\n",
    "        \n",
    "        # Update Process Covariance Matrix\n",
    "        P = (np.identity(len(K)) - K.dot(H)).dot(P)\n",
    "    results.append(X13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9db329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Kalman Filter State Matrix:\\n\", X,'\\n The expected_delta_phi is:',X[0]*180/np.pi,'\\n it was:', a12*180/np.pi, \n",
    "#       '\\n and it should be:',df_corr.ex_phi12.mean()*180/np.pi, '\\n error befor:', abs(df_corr.ex_phi12.mean()-a12)*180/np.pi,\n",
    "#      '\\n error after:', abs(df_corr.ex_phi12.mean()*180/np.pi-X[0]*180/np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b15c64c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Kalman Filter State Matrix:\\n\", X,'\\n The expected_delta_phi with kalman_filter is:',X23[0]*180/np.pi,\n",
    "#       '\\n expected_delta_phi was:', a23*180/np.pi, \n",
    "#       '\\n and it should be:',df_corr.ex_phi12.mean()*180/np.pi, '\\n error befor:', abs(df_corr.ex_phi12.mean()-a23)*180/np.pi,\n",
    "#      '\\n error after:', abs(df_corr.ex_phi12.mean()*180/np.pi-X23[0]*180/np.pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ae288428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Kalman Filter State Matrix:\\n\", X13,'\\n The expected_delta_phi after kalman filter is:',X13[0]*180/np.pi,\n",
    "#       '\\n expected_delta_phi was:', a13*360/np.pi, \n",
    "#       '\\n and it should be:',df_corr.ex_phi12.mean()*360/np.pi, \n",
    "#       '\\n error befor:', abs(df_corr.ex_phi12.mean()-a13)*360/np.pi,\n",
    "#      '\\n error after:', abs(df_corr.ex_phi12.mean()*2-X13[0])*180/np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3c2cbf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.21489327]\n"
     ]
    }
   ],
   "source": [
    "kalman_filter_error = df_corr.ex_phi12.mean()*180/np.pi - (X[0]+X23[0]+X13[0])/4*180/np.pi\n",
    "print(kalman_filter_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b25c19f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([67.76961575])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (X[0]+X23[0]+X13[0])/4*180/np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e8093c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_correction_error = df_corr.ex_phi12.mean()*180/np.pi - (np.average(average_perchannel['ave_phi12'])*180/np.pi+ np.average(average_perchannel['ave_phi23'])*180/np.pi+ np.average(average_perchannel['ave_phi13'])*90/np.pi)/3\n",
    "corrected_error =  df_corr.ex_phi12.mean()*180/np.pi - (np.average(average_perchannel['corrected_phi12'])*180/np.pi+ np.average(average_perchannel['corrected_phi13'])*90/np.pi+ np.average(average_perchannel['corrected_phi23'])*180/np.pi)/3\n",
    "no_correction_error_opt = df_corr.ex_phi12.mean()*180/np.pi - (np.average(average_perchannel['ave_phi12_opt'])*180/np.pi+ np.average(average_perchannel['ave_phi23_opt'])*180/np.pi+ np.average(average_perchannel['ave_phi13_opt'])*90/np.pi)/3\n",
    "corrected_error_opt =  df_corr.ex_phi12.mean()*180/np.pi - (np.average(average_perchannel['corrected_phi12_opt'])*180/np.pi+ np.average(average_perchannel['corrected_phi13_opt'])*90/np.pi+ np.average(average_perchannel['corrected_phi23_opt'])*180/np.pi)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33fe7b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_corr.ex_phi12.mean()*180/np.pi - (X[0]+X23[0]+X13[0])/3*180/np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81465232",
   "metadata": {},
   "source": [
    "### Compare the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0d41bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No_correction_error: 29.50697914699589 \n",
      " Corrected_error: 0.5698244892090685 \n",
      " No__correction_error_opt: 36.140200936015496 \n",
      " Corrected_error_opt: 7.203046278228683 \n",
      " kalman_filter_error(opt): [7.21489327]\n"
     ]
    }
   ],
   "source": [
    "print(' No_correction_error:', no_correction_error , \n",
    "     '\\n Corrected_error:', corrected_error,\n",
    "     '\\n No__correction_error_opt:', no_correction_error_opt,\n",
    "     '\\n Corrected_error_opt:' , corrected_error_opt, \n",
    "     '\\n kalman_filter_error(opt):' , kalman_filter_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4beb9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of error decrease, using kalamn filter is: [0.16447192] %\n"
     ]
    }
   ],
   "source": [
    "error_decrease = abs(corrected_error_opt-kalman_filter_error)*100/abs(corrected_error_opt)\n",
    "print('The percentage of error decrease, using kalamn filter is:', error_decrease, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c31bed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
